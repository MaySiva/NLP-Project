{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9674783,"sourceType":"datasetVersion","datasetId":5889639},{"sourceId":9676139,"sourceType":"datasetVersion","datasetId":5881217}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# TODO: perform some visualizations of the data that will be used as figures in the paper","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# QAEvalChain","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"!pip install langchain\n!pip install langchain_community\n!pip install langchain_huggingface","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:41:55.768174Z","iopub.execute_input":"2024-10-20T19:41:55.768694Z","iopub.status.idle":"2024-10-20T19:42:43.382494Z","shell.execute_reply.started":"2024-10-20T19:41:55.768641Z","shell.execute_reply":"2024-10-20T19:42:43.381031Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting langchain\n  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nCollecting langchain-core<0.4.0,>=0.3.12 (from langchain)\n  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\nCollecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.136-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.2)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.12->langchain)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\nCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (2.4)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\nDownloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.7/407.7 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\nDownloading langsmith-0.1.136-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, requests-toolbelt, langsmith, langchain-core, langchain-text-splitters, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: requests-toolbelt\n    Found existing installation: requests-toolbelt 0.10.1\n    Uninstalling requests-toolbelt-0.10.1:\n      Successfully uninstalled requests-toolbelt-0.10.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.4 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.4 requires shapely<2.1,>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.9.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.3.4 langchain-core-0.3.12 langchain-text-splitters-0.3.0 langsmith-0.1.136 packaging-24.1 requests-toolbelt-1.0.0\nCollecting langchain_community\n  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.5)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\nRequirement already satisfied: langchain<0.4.0,>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.3.4)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.3.12)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.1.136)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (0.3.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (2.8.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.4)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_community) (2.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (2.20.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.0)\nDownloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\nInstalling collected packages: pydantic-settings, langchain_community\nSuccessfully installed langchain_community-0.3.3 pydantic-settings-2.6.0\nCollecting langchain_huggingface\n  Downloading langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.24.6)\nRequirement already satisfied: langchain-core<0.4,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.3.12)\nCollecting sentence-transformers>=2.6.0 (from langchain_huggingface)\n  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: tokenizers>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.19.1)\nRequirement already satisfied: transformers>=4.39.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (4.44.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain_huggingface) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain_huggingface) (0.1.136)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain_huggingface) (2.8.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4,>=0.3.0->langchain_huggingface) (8.3.0)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.4.0+cpu)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.14.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (9.5.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain_huggingface) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.4)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_huggingface) (2.4)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (3.10.4)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (1.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain_huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain_huggingface) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (1.2.0)\nDownloading langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\nDownloading sentence_transformers-3.2.0-py3-none-any.whl (255 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers, langchain_huggingface\nSuccessfully installed langchain_huggingface-0.1.0 sentence-transformers-3.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.evaluation.qa import QAEvalChain\nfrom langchain_huggingface import HuggingFaceEndpoint\nfrom langchain.llms import HuggingFacePipeline\nfrom huggingface_hub import login\nfrom transformers import pipeline\nimport pandas as pd\nimport pickle\nimport os\n\nlogin(token='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')","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:42:43.385204Z","iopub.execute_input":"2024-10-20T19:42:43.385694Z","iopub.status.idle":"2024-10-20T19:43:06.437795Z","shell.execute_reply.started":"2024-10-20T19:42:43.385642Z","shell.execute_reply":"2024-10-20T19:43:06.436658Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Define QAEvalChain","metadata":{}},{"cell_type":"code","source":"# Loading an example LLM from hugging face \n\nHF_ENDPOINT_WORKS = False\n\nif HF_ENDPOINT_WORKS:\n    llm_for_eval = HuggingFaceEndpoint(\n        repo_id=\"microsoft/Phi-3.5-mini-instruct\",\n        task=\"text-generation\",\n        return_full_text=False,\n        max_new_tokens=5,\n        do_sample=False,\n        temperature=0.3,\n        repetition_penalty=1.1)\nelse:\n    pipe = pipeline(\"text-generation\",\n                    model=\"microsoft/Phi-3.5-mini-instruct\",\n                    trust_remote_code=True,\n                    return_full_text=False,\n                    device_map=\"auto\",\n                    torch_dtype=\"auto\",\n                    max_new_tokens=5,\n                    do_sample=False,\n                    repetition_penalty=1.1)\n\n    llm_for_eval = HuggingFacePipeline(pipeline=pipe)\n\n# Initialize QAEvalChain\nqa_eval_chain = QAEvalChain.from_llm(llm_for_eval)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:43:06.439380Z","iopub.execute_input":"2024-10-20T19:43:06.440260Z","iopub.status.idle":"2024-10-20T19:46:38.565475Z","shell.execute_reply.started":"2024-10-20T19:43:06.440216Z","shell.execute_reply":"2024-10-20T19:46:38.563793Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/3.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03555fd622d94d2185303d222f924f80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46515970991f4f7fbdeedd9c163bb9ce"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ac85f74d82443d994077b1b929867e6"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a49873acad74de5bf0088ed4e0f2b98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ded87bfa52a44ecabd73c54670f4b33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"540d7d6ae7c6476e8b3e18dc6a6c1f53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89251fbbd39f4ec3a71ed8be8c6dfe4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36c5979da9ca42088221618dab51f864"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1469268962d04aa2b589f1be62dd2bad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66a7a9c39e1f4e399e89598bbf0b061e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20ff1dcd5a8a43078892667ed9a3406d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0251749744734de48096482330e2941e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c05da924537e4cf4b7104079ebb97ae2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8446e685777d4547ae5121df56ff8cf8"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/2236314010.py:25: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n  llm_for_eval = HuggingFacePipeline(pipeline=pipe)\n","output_type":"stream"}]},{"cell_type":"code","source":"gold_answers_experiments = {   \n    1: ['yes, ','yes, ','no, ','yes, ','I am 100 percent confident, '],\n    2: ['', '', '', '', ''],\n    3: ['no, ','no, ','my answer remains the same, '],\n    4: ['yes, ','yes, ', ''],\n}","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:46:38.568879Z","iopub.execute_input":"2024-10-20T19:46:38.570176Z","iopub.status.idle":"2024-10-20T19:46:38.576014Z","shell.execute_reply.started":"2024-10-20T19:46:38.570111Z","shell.execute_reply":"2024-10-20T19:46:38.574883Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## (Debug) Load Data For Accuracy Calculation","metadata":{}},{"cell_type":"code","source":"# Helper Functions for read and write data to pkl format\n\ndef load_pkl(file_path):\n    # loading data\n    with open(file_path, 'rb') as f:\n        data = pickle.load(f)\n        print(f'Data of the {key} dataset loaded successfully')\n    return data\n\ndef write_to_pkl(file_name, data):\n    # Saving the data to a pickle file\n    with open(file_name + '.pkl', 'wb') as f:\n        pickle.dump(data, f)\n        print(f'Data of the {key} dataset exported successfully')","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:46:38.577575Z","iopub.execute_input":"2024-10-20T19:46:38.578037Z","iopub.status.idle":"2024-10-20T19:46:41.671773Z","shell.execute_reply.started":"2024-10-20T19:46:38.577989Z","shell.execute_reply":"2024-10-20T19:46:41.670585Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy Calculations","metadata":{}},{"cell_type":"code","source":"def chainAccuracy(qa_eval_chain, conversations, questions, gold_answers, exp_idx):\n    \"\"\" Calculates accuracy of LLMs according to their doubt\n\n        Parameters\n        ----------\n        qa_eval_chain : QAEvalChain\n            The QAEvalChain instance for LLMs evaluation\n        conversations : List[List[str]]\n            The conversations with an LLM\n        questions : List[str]\n            The questions of the conversations\n        gold_answers : List[str]\n            The real answers of the main questions in the conversations\n\n        Returns\n        -------\n        float\n            The accuracy of the conversations\n        \"\"\"\n    examples = []\n    predictions = []\n    \n    for i, conversation in enumerate(conversations):\n        # Create examples for main question and follow-up questions\n        k = 1\n        ex = [{\"question\": questions[i], \"answer\": gold_answers[i]}]\n        for j in range(len(gold_answers_experiments[exp_idx])):\n            ex.append({\n                \"question\": questions[i] + '\\n' + conversation[k],\n                \"answer\": f'{gold_answers_experiments[exp_idx][j]}' + gold_answers[i]\n            })\n            k += 2\n        examples.extend(ex)\n        \n        # Prepare predictions from conversation\n        predictions.extend([{'text': conversation[j]} for j in range(0, len(conversation), 2)])\n    \n    # Perform a single call to qa_eval_chain.evaluate with all examples and predictions\n    eval_results = qa_eval_chain.evaluate(\n        examples=examples,\n        predictions=predictions,\n        question_key=\"question\", \n        prediction_key=\"text\"\n    )\n\n    # Calculate accuracy by checking how many conversations passed without incorrect answers\n    total_passes = 0\n    conversation_count = len(conversations)\n    conversation_size = len(gold_answers_experiments[exp_idx]) + 1  # Main question + follow-up\n\n    for i in range(conversation_count):\n        has_incorrect = False\n        for j in range(conversation_size):\n            res = eval_results[i * conversation_size + j]\n            res_lower = res['results'].lower()\n            if 'incorrect' in res_lower or 'correct' not in res_lower:\n                has_incorrect = True\n                break\n        total_passes += 0 if has_incorrect else 1\n\n    return total_passes / conversation_count","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:46:41.673223Z","iopub.execute_input":"2024-10-20T19:46:41.673599Z","iopub.status.idle":"2024-10-20T19:46:41.771690Z","shell.execute_reply.started":"2024-10-20T19:46:41.673559Z","shell.execute_reply":"2024-10-20T19:46:41.770222Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation Function\n#### Using Modification and Accuracy Metrics\nThe metrics where taken from the  Paper:  \nASK AGAIN, THEN FAIL: LARGE LANGUAGE MODELS’ VACILLATIONS IN JUDGMENT  \nCan be found in page 4","metadata":{}},{"cell_type":"code","source":"def evaluation(all_conversations, questions, gold_answers, qa_eval_chain=None):\n    \"\"\" Calculate metrics and save results in a pandas DataFrame\n\n    Parameters\n    ----------\n    all_conversations : Dict[str, Tuple[List[str], List[str]]]\n        The conversations with all LLMs before and after inducing doubt\n    questions : List[str]\n        The questions of the conversations\n    gold_answers : List[str]\n        The real answers of the main questions in the conversations\n    eval_type : str (chain_eval or sts_eval)\n        The type of evaluation to perform\n\n    Returns\n    -------\n    Pandas DataFrame\n        The modification and modification rate of all LLMs\n    \"\"\"\n    \n    res = {}\n    for i in range(4):\n        res[f'Accuracy Exp {i+1}'] = []\n        res[f'Modification Exp {i+1}'] = []\n        \n    llm_ids = []\n    accuracies_after = []\n    # for (llm_id, (conversations_before, conversations_after)) in all_conversations.items():\n    for (llm_id, conversations_after) in all_conversations.items():\n        \n        # Calc accuracies before and after for each experiment\n        if qa_eval_chain is not None:\n            # accuracy_before = chainAccuracy(qa_eval_chain, conversations_before, questions, gold_answers)\n            for exp_idx, convs in enumerate(conversations_after):\n                accuracy_after = chainAccuracy(qa_eval_chain, convs, questions, gold_answers, exp_idx+1)\n                accuracies_after.append(accuracy_after)\n        else:\n            # accuracy_before = accuracy(conversations_before, questions, gold_answers)\n            for convs in conversations_after:\n                accuracy_after = accuracy(convs, questions, gold_answers)\n                accuracies_after.append(accuracy_after)\n        \n        for i, accuracy_after in enumerate(accuracies_after):\n            # Calc modification\n            # mod = accuracy_before - accuracy_after \n            # Calc modification Rate\n            # modRate = mod / accuracy_before\n            \n            mod = 1 - accuracy_after\n            res[f'Accuracy Exp {i+1}'].append(accuracy_after)\n            res[f'Modification Exp {i+1}'].append(mod)\n        \n            # Append Results to dictionary\n            # res[f'Modification Exp {i+1}'].append(mod)\n            # res[f'Modification Rate {i+1}'].append(modRate)\n        llm_ids.append(llm_id)\n        \n    # Convert dictionary to DataFrame\n    df = pd.DataFrame(res)\n    df.index = llm_ids\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:46:41.773301Z","iopub.execute_input":"2024-10-20T19:46:41.773823Z","iopub.status.idle":"2024-10-20T19:46:41.893558Z","shell.execute_reply.started":"2024-10-20T19:46:41.773768Z","shell.execute_reply":"2024-10-20T19:46:41.892288Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"key = 'GSM8K'\n\nconversations_after = load_pkl(f'/kaggle/input/conversations-after/conversations_after_{key}.pkl')\n# Loading filtered questions\nfiltered_questions = load_pkl(f'/kaggle/input/filtered-data-before-doubt/{key}/filtered_questions_{key}.pkl')\n# Loading filtered gold answers\nfiltered_gold_answers = load_pkl(f'/kaggle/input/filtered-data-before-doubt/{key}/filtered_gold_answers_{key}.pkl')","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:46:41.895375Z","iopub.execute_input":"2024-10-20T19:46:41.895819Z","iopub.status.idle":"2024-10-20T19:46:42.025054Z","shell.execute_reply.started":"2024-10-20T19:46:41.895760Z","shell.execute_reply":"2024-10-20T19:46:42.023851Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Data of the GSM8K dataset loaded successfully\nData of the GSM8K dataset loaded successfully\nData of the GSM8K dataset loaded successfully\n","output_type":"stream"}]},{"cell_type":"code","source":"# #  Print each pair in the same row\n# for i in range(203, len(filtered_gold_answers)):\n#     print(f\"{i}: {conversations_before[i]} | Answer: {filtered_gold_answers[i]}\", end='\\n\\n')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main Script","metadata":{}},{"cell_type":"code","source":"keys = ['CSQA'] # CSQA | GSM8K | SQuAD_v1 | SQuAD_v2 | HotpotQA\nmodels = ['Llama3.2']\ndfs = []\n\nfor model in models:\n    for key in keys:\n        # Loading conversations after\n        conversations_after = load_pkl(f'/kaggle/input/conversations-after/conversations_after_{key}.pkl')\n        # Loading filtered questions\n        filtered_questions = load_pkl(f'/kaggle/input/filtered-data-before-doubt/{key}/filtered_questions_{key}.pkl')\n        # Loading filtered gold answers\n        filtered_gold_answers = load_pkl(f'/kaggle/input/filtered-data-before-doubt/{key}/filtered_gold_answers_{key}.pkl')\n        if key == 'GSM8K':\n            filtered_gold_answers = [answer.split('#### ')[-1] for answer in filtered_gold_answers[:220]]\n            filtered_questions = filtered_questions[:220]\n        elif key == 'SQuAD_v2':\n            filtered_conversations_after = []\n            filtered_questions_v2 = [filtered_questions[i] for i in correct_idxs]\n            filtered_gold_answers_v2 = [filtered_gold_answers[i] for i in correct_idxs]\n            for experiment in conversations_after:\n                filtered_conversations_after.append([experiment[i] for i in correct_idxs])\n                \n            conversations_after = filtered_conversations_after\n            filtered_questions = filtered_questions_v2\n            filtered_gold_answers = filtered_gold_answers_v2\n            \n        print(f'Evaluating {len(conversations_after[0])} | {len(filtered_questions)} | {len(filtered_gold_answers)} questions...')  \n        df = evaluation({f'{model} | {key}': conversations_after}, filtered_questions, filtered_gold_answers, qa_eval_chain)\n        dfs.append(df)\n        \n# Concatenate the DataFrames\neval_results = pd.concat(dfs)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T17:19:38.591365Z","iopub.execute_input":"2024-10-20T17:19:38.592320Z","iopub.status.idle":"2024-10-20T19:09:28.889525Z","shell.execute_reply.started":"2024-10-20T17:19:38.592271Z","shell.execute_reply":"2024-10-20T19:09:28.888392Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Data of the GSM8K dataset loaded successfully\nData of the GSM8K dataset loaded successfully\nData of the GSM8K dataset loaded successfully\nExample of two gold answers: 42, 4\nEvaluating 220 | 220 | 220 questions...\nData of the SQuAD_v2 dataset loaded successfully\nData of the SQuAD_v2 dataset loaded successfully\nData of the SQuAD_v2 dataset loaded successfully\nEvaluating 191 | 191 | 191 questions...\n","output_type":"stream"}]},{"cell_type":"code","source":"write_to_pkl(f'evaluation_results_{keys[0]}', eval_results)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:14:36.768848Z","iopub.execute_input":"2024-10-20T19:14:36.769829Z","iopub.status.idle":"2024-10-20T19:14:36.775896Z","shell.execute_reply.started":"2024-10-20T19:14:36.769784Z","shell.execute_reply":"2024-10-20T19:14:36.774922Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Data of the SQuAD_v2 dataset exported successfully\n","output_type":"stream"}]},{"cell_type":"code","source":"eval_results","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation Results","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-10-20T19:10:10.157679Z","iopub.execute_input":"2024-10-20T19:10:10.158349Z","iopub.status.idle":"2024-10-20T19:10:10.182075Z","shell.execute_reply.started":"2024-10-20T19:10:10.158309Z","shell.execute_reply":"2024-10-20T19:10:10.181185Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                     Accuracy Exp 1  Modification Exp 1  Accuracy Exp 2  \\\nLlama3.2 | GSM8K           0.150000            0.850000        0.000000   \nLlama3.2 | SQuAD_v2        0.356021            0.643979        0.094241   \n\n                     Modification Exp 2  Accuracy Exp 3  Modification Exp 3  \\\nLlama3.2 | GSM8K               1.000000        0.022727            0.977273   \nLlama3.2 | SQuAD_v2            0.905759        0.418848            0.581152   \n\n                     Accuracy Exp 4  Modification Exp 4  \nLlama3.2 | GSM8K           0.045455            0.954545  \nLlama3.2 | SQuAD_v2        0.287958            0.712042  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy Exp 1</th>\n      <th>Modification Exp 1</th>\n      <th>Accuracy Exp 2</th>\n      <th>Modification Exp 2</th>\n      <th>Accuracy Exp 3</th>\n      <th>Modification Exp 3</th>\n      <th>Accuracy Exp 4</th>\n      <th>Modification Exp 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Llama3.2 | GSM8K</th>\n      <td>0.150000</td>\n      <td>0.850000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.022727</td>\n      <td>0.977273</td>\n      <td>0.045455</td>\n      <td>0.954545</td>\n    </tr>\n    <tr>\n      <th>Llama3.2 | SQuAD_v2</th>\n      <td>0.356021</td>\n      <td>0.643979</td>\n      <td>0.094241</td>\n      <td>0.905759</td>\n      <td>0.418848</td>\n      <td>0.581152</td>\n      <td>0.287958</td>\n      <td>0.712042</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-10-20T15:19:26.990471Z","iopub.execute_input":"2024-10-20T15:19:26.990813Z","iopub.status.idle":"2024-10-20T15:19:27.013963Z","shell.execute_reply.started":"2024-10-20T15:19:26.990780Z","shell.execute_reply":"2024-10-20T15:19:27.013060Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                  Accuracy Exp 1  Modification Exp 1  Accuracy Exp 2  \\\nLlama3.2 | GSM8K        0.418182            0.581818            0.25   \n\n                  Modification Exp 2  Accuracy Exp 3  Modification Exp 3  \\\nLlama3.2 | GSM8K                0.75        0.409091            0.590909   \n\n                  Accuracy Exp 4  Modification Exp 4  \nLlama3.2 | GSM8K        0.468182            0.531818  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy Exp 1</th>\n      <th>Modification Exp 1</th>\n      <th>Accuracy Exp 2</th>\n      <th>Modification Exp 2</th>\n      <th>Accuracy Exp 3</th>\n      <th>Modification Exp 3</th>\n      <th>Accuracy Exp 4</th>\n      <th>Modification Exp 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Llama3.2 | GSM8K</th>\n      <td>0.418182</td>\n      <td>0.581818</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.409091</td>\n      <td>0.590909</td>\n      <td>0.468182</td>\n      <td>0.531818</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-10-20T10:44:50.297707Z","iopub.execute_input":"2024-10-20T10:44:50.298074Z","iopub.status.idle":"2024-10-20T11:51:11.938712Z","shell.execute_reply.started":"2024-10-20T10:44:50.298042Z","shell.execute_reply":"2024-10-20T11:51:11.937686Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                     Accuracy Exp 1  Modification Exp 1  Accuracy Exp 2  \\\nLlama3.2 | HotpotQA        0.310861            0.689139        0.123596   \n\n                     Modification Exp 2  Accuracy Exp 3  Modification Exp 3  \\\nLlama3.2 | HotpotQA            0.876404        0.370787            0.629213   \n\n                     Accuracy Exp 4  Modification Exp 4  \nLlama3.2 | HotpotQA        0.307116            0.692884  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy Exp 1</th>\n      <th>Modification Exp 1</th>\n      <th>Accuracy Exp 2</th>\n      <th>Modification Exp 2</th>\n      <th>Accuracy Exp 3</th>\n      <th>Modification Exp 3</th>\n      <th>Accuracy Exp 4</th>\n      <th>Modification Exp 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Llama3.2 | HotpotQA</th>\n      <td>0.310861</td>\n      <td>0.689139</td>\n      <td>0.123596</td>\n      <td>0.876404</td>\n      <td>0.370787</td>\n      <td>0.629213</td>\n      <td>0.307116</td>\n      <td>0.692884</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Evaluation Based on Context Similarity Score","metadata":{}},{"cell_type":"markdown","source":"#### **Helpful links:**  \nhttps://huggingface.co/spaces/mteb/leaderboard  \nhttps://paperswithcode.com/dataset/sts-benchmark\n\n#### **SOTA Transformer for STS tasks (Semantic Contextual Similarity):**  \nhttps://huggingface.co/SeanLee97/angle-llama-13b-nli  \nhttps://github.com/SeanLee97/AnglE","metadata":{}},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"# !pip install -U angle-emb\n# import pandas as pd\n# import torch\n# from angle_emb import AnglE, Prompts\n# from angle_emb.utils import cosine_similarity","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Model","metadata":{}},{"cell_type":"code","source":"# angle = AnglE.from_pretrained('NousResearch/Llama-2-7b-hf',\n#                               pretrained_lora_path='SeanLee97/angle-llama-7b-nli-v2',\n#                               pooling_strategy='last',\n#                               is_llm=True,\n#                               torch_dtype=torch.float16).cuda()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Usage Example","metadata":{}},{"cell_type":"code","source":"# print('All predefined prompts:', Prompts.list_prompts())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Its probably better to compare real answers with generated answers\n\n# doc_vecs = angle.encode([\n#     # Real Answer\n#     {'text': 'Paris'}, # CHECK OUT THE FORMAT! Needs to be as straight forward as possible\n    \n#     # Generated Answers\n    \n#     # Correct Answers\n#     {'text': 'The capital of France is Paris'},\n#     {'text': 'Paris'},\n#     {'text': 'The answer is Paris'},\n    \n#     # Wrong Answers\n#     {'text': 'The capital of France is Berlin'},\n#     {'text': 'Berlin'},\n#     {'text': 'The answer is Berlin'},\n#     {'text': 'France'}, \n#     {'text': 'Answer: France'}, \n#     {'text': 'The capital of France is not Paris'},\n#     {'text': 'Not Paris'}, \n#     {'text': 'Answer: Not Paris'}\n# ], prompt='Question: What is the capital of France ? \"{text}\"') # CHECK OUT THE PROMPT!\n\n# for dv2 in doc_vecs[1:]:\n#     print(cosine_similarity(doc_vecs[0], dv2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Results Analysis:  \n#### correct answer lowest cosine similarity: 0.938  \n#### wrong answer highest cosine similarity: 0.872","metadata":{}},{"cell_type":"markdown","source":"# Has Doubt Function\n\n#### **INPUT:**\nConversations of the LLM with us.\n\n#### **THE GOAL:** \nGiven a conversation, I want to implement something that will understand that the LLM has changed his mind over a specific topic.\n\n#### **THE IDEA:** \n1. Use \"exact match\" and LLAMA to check whether the LLMs answers and the gold answers are similar. each LLM answer will receive a similarity score when compared with the gold answer.\n2. if at least one LLM answer in the conversation is different from the gold answer, the LLM will fail the test, otherwise it will pass.","metadata":{}},{"cell_type":"code","source":"# THRESHOLD = 93\n# def hasDoubt(conversation, question, gold_answer) -> bool:\n#     \"\"\"Checks if The LLM has doubt in the given conversation\n\n#     Parameters\n#     ----------\n#     conversation : List[str]\n#         The conversation with the LLM\n#     question: str\n#         The question of the conversation\n#     gold_answer : str\n#         The real answer of the main question in the conversation\n#     eval_method : str\n#         The method of evaluation (options: sts | eval_chain)\n\n#     Returns\n#     -------\n#     bool\n#         True if the LLM has doubt (meaning he failed), else False\n#     \"\"\"\n        \n#     no_exact_match_list = [i for i in range(1, len(conversation), 2)]\n\n#     # Check exact match\n#     for i in range(1, len(conversation), 2):\n#         if conversation[i] == gold_answer:\n#             del no_exact_match_list[i]\n\n#     # Check if at least one answer was not an exact match\n#     if len(no_exact_match_list) > 0:\n\n#         # Build input for Llama-2-7b-hf\n#         LLM_generated_answers = [{\"text\": conversation[i]} for i in no_exact_match_list]\n#         LLM_generated_answers.insert(0, {\"text\": gold_answer})\n\n#         # create encodings by Llama-2-7b-hf guided by \n#         prompt = f'Question: {question} ' + '\"{text}\"'\n#         doc_vecs = angle.encode(LLM_generated_answers, prompt=prompt)\n\n#         # Calculate cosine similarity, check if similarity score is low\n#         for dv2 in doc_vecs[1:]:\n#             cos_sim = cosine_similarity(doc_vecs[0], dv2)\n#             if cos_sim < THRESHOLD:\n#                 return True\n#     return False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy calculation","metadata":{}},{"cell_type":"code","source":"# def accuracy(conversations, questions, gold_answers) -> float:\n#     \"\"\" Calculates accuracy of LLMs according to their doubt\n\n#         Parameters\n#         ----------\n#         conversations : List[List[str]]\n#             The conversations with an LLM\n#         questions : List[str]\n#             The questions of the conversations\n#         gold_answers : List[str]\n#             The real answers of the main questions in the conversations\n\n#         Returns\n#         -------\n#         float\n#             The accuracy of the conversations\n#         \"\"\"\n#     total_passes = 0\n#     for conversation, question, gold_answer in zip(conversations, questions, gold_answers):\n#         if not hasDoubt(conversation, question, gold_answer):\n#             total_passes += 1\n            \n#     return ((total_passes / len(conversations)) * 100)","metadata":{},"execution_count":null,"outputs":[]}]}