{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# TODO: perform some visualizations of the data that will be used as figures in the paper","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Helpful links:**  \nhttps://huggingface.co/spaces/mteb/leaderboard  \nhttps://paperswithcode.com/dataset/sts-benchmark\n\n#### **SOTA Transformer for STS tasks (Semantic Contextual Similarity):**  \nhttps://huggingface.co/SeanLee97/angle-llama-13b-nli  \nhttps://github.com/SeanLee97/AnglE","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"!pip install -U angle-emb\nimport pandas as pd\nimport torch\nfrom angle_emb import AnglE, Prompts\nfrom angle_emb.utils import cosine_similarity","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:45:19.033355Z","iopub.execute_input":"2024-10-01T21:45:19.033778Z","iopub.status.idle":"2024-10-01T21:46:00.691533Z","shell.execute_reply.started":"2024-10-01T21:45:19.033729Z","shell.execute_reply":"2024-10-01T21:46:00.690325Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting angle-emb\n  Downloading angle_emb-0.5.1-py3-none-any.whl.metadata (19 kB)\nCollecting bitsandbytes (from angle-emb)\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: boltons in /opt/conda/lib/python3.10/site-packages (from angle-emb) (24.0.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from angle-emb) (2.21.0)\nCollecting peft (from angle-emb)\n  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from angle-emb) (3.10.0)\nRequirement already satisfied: transformers>=4.32.1 in /opt/conda/lib/python3.10/site-packages (from angle-emb) (4.44.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from angle-emb) (1.14.0)\nCollecting einops (from angle-emb)\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from angle-emb) (0.17.7)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from angle-emb) (1.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.1->angle-emb) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.1->angle-emb) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.1->angle-emb) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.1->angle-emb) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.1->angle-emb) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.1->angle-emb) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.1->angle-emb) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.1->angle-emb) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.1->angle-emb) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.1->angle-emb) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes->angle-emb) (2.4.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->angle-emb) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->angle-emb) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->angle-emb) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->angle-emb) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->angle-emb) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->angle-emb) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->angle-emb) (3.9.5)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft->angle-emb) (5.9.3)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft->angle-emb) (0.33.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->angle-emb) (0.2.13)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->angle-emb) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->angle-emb) (3.5.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb->angle-emb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->angle-emb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->angle-emb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb->angle-emb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb->angle-emb) (3.20.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->angle-emb) (2.13.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->angle-emb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb->angle-emb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->angle-emb) (1.16.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->angle-emb) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->angle-emb) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->angle-emb) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->angle-emb) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->angle-emb) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->angle-emb) (4.0.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->angle-emb) (4.0.11)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.32.1->angle-emb) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.32.1->angle-emb) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.32.1->angle-emb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.32.1->angle-emb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.32.1->angle-emb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.32.1->angle-emb) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes->angle-emb) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes->angle-emb) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes->angle-emb) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->angle-emb) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->angle-emb) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->angle-emb) (2024.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->angle-emb) (5.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes->angle-emb) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes->angle-emb) (1.3.0)\nDownloading angle_emb-0.5.1-py3-none-any.whl (29 kB)\nDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.13.0-py3-none-any.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops, bitsandbytes, peft, angle-emb\nSuccessfully installed angle-emb-0.5.1 bitsandbytes-0.44.1 einops-0.8.0 peft-0.13.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"code","source":"angle = AnglE.from_pretrained('NousResearch/Llama-2-7b-hf',\n                              pretrained_lora_path='SeanLee97/angle-llama-7b-nli-v2',\n                              pooling_strategy='last',\n                              is_llm=True,\n                              torch_dtype=torch.float16).cuda()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:46:00.693808Z","iopub.execute_input":"2024-10-01T21:46:00.695048Z","iopub.status.idle":"2024-10-01T21:47:29.739634Z","shell.execute_reply.started":"2024-10-01T21:46:00.694996Z","shell.execute_reply":"2024-10-01T21:47:29.738585Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ab1afb65087432d917b6433d85f9457"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b717252dca3d442b86d2f082b6e82166"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"367b78524233429aa2a7f2174dc5b8f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f193eb06d2214ca498992d66cdc400c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ebadb2651eb4e37a2609773a4496c58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf8fa1c51574a79b7b99e1f9062d89a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3585072eb344ad9ade12ea225b49ea5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8635af8bff4345d88a3d026577177e8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2dac30218354be9b4347d3ba59f7e94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38f56c42b041421c8d7dd9502c41e35d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e580597f0a174aa19263c798f66180b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1702b8b79ba84630a91209bbf4bbe56f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.bin:   0%|          | 0.00/320M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32d25efff0714ea3852bef6f4c6e8394"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Model Usage Example","metadata":{}},{"cell_type":"code","source":"print('All predefined prompts:', Prompts.list_prompts())","metadata":{"execution":{"iopub.status.busy":"2024-10-01T21:47:29.740924Z","iopub.execute_input":"2024-10-01T21:47:29.743179Z","iopub.status.idle":"2024-10-01T21:47:29.749797Z","shell.execute_reply.started":"2024-10-01T21:47:29.743127Z","shell.execute_reply":"2024-10-01T21:47:29.748343Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Prompts.A = 'Summarize sentence \"{text}\" in one word:\"'\nPrompts.B = 'You can only output one word. Summarize \"{text}\":\"'\nPrompts.C = 'Represent this sentence for searching relevant passages: {text}'\nAll predefined prompts: None\n","output_type":"stream"}]},{"cell_type":"code","source":"# Its probably better to compare real answers with generated answers\ndoc_vecs = angle.encode([\n    # Real Answer\n    {'text': 'Paris'}, # CHECK OUT THE FORMAT!\n    \n    # Generated Answers\n    \n    # Correct Answers\n    {'text': 'The capital of France is Paris'},\n    {'text': 'Paris'},\n    {'text': 'The answer is Paris'},\n    \n    # Wrong Answers\n    {'text': 'The capital of France is Berlin'},\n    {'text': 'Berlin'},\n    {'text': 'The answer is Berlin'},\n    {'text': 'France'}, \n    {'text': 'Answer: France'}, \n    {'text': 'The capital of France is not Paris'},\n    {'text': 'Not Paris'}, \n    {'text': 'Answer: Not Paris'}\n], prompt='Question: What is the capital of France ? \"{text}\"') # CHECK OUT THE PROMPT!\n\nfor dv2 in doc_vecs[1:]:\n    print(cosine_similarity(doc_vecs[0], dv2))","metadata":{"execution":{"iopub.status.busy":"2024-10-01T22:16:34.312978Z","iopub.execute_input":"2024-10-01T22:16:34.313407Z","iopub.status.idle":"2024-10-01T22:16:34.943656Z","shell.execute_reply.started":"2024-10-01T22:16:34.313359Z","shell.execute_reply":"2024-10-01T22:16:34.942329Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"0.9385602332603996\n0.9999999973163464\n0.9437088099355337\n0.7315496672265994\n0.8406786008563676\n0.7723152540915147\n0.851462490181592\n0.872062642832054\n0.6906014976386847\n0.8295816874703805\n0.7741671864250584\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Results Analysis:  \n#### correct answer lowest cosine similarity: 0.938  \n#### wrong answer highest cosine similarity: 0.872","metadata":{}},{"cell_type":"markdown","source":"# Has Doubt Function\n\n#### **INPUT:**\nConversations of the LLM with us.\n\n#### **THE GOAL:** \nGiven a conversation, I want to implement something that will understand that the LLM has changed his mind over a specific topic.\n\n#### **THE IDEA:** \n1. Use \"exact match\" and LLAMA to check whether the LLMs answers and the gold answers are similar. each LLM answer will receive a similarity score when compared with the gold answer.\n2. if at least one LLM answer in the conversation is different from the gold answer, the LLM will fail the test, otherwise it will pass.","metadata":{}},{"cell_type":"code","source":"THRESHOLD = 93 # Hyperparameter\n\n\ndef hasDoubt(conversation, gold_answer) -> bool:\n    \"\"\"Checks if The LLM has doubt in the given conversation\n\n    Parameters\n    ----------\n    conversation : List[str]\n        The conversation with the LLM\n    gold_answer : str\n        The real answer of the main question in the conversation\n\n    Returns\n    -------\n    bool\n        True if the LLM has doubt (meaning he failed), else False\n    \"\"\"\n    \n    no_exact_match_list = [i for i in range(1, len(conversation), 2)]\n    \n    # Check exact match\n    for i in range(1, len(conversation), 2):\n        if conversation[i] == gold_answer:\n            del no_exact_match_list[i]\n    \n    # Check if at least one answer was not an exact match\n    if len(no_exact_match_list) > 0:\n        \n        # Build input for Llama-2-7b-hf\n        LLM_generated_answers = [{\"text\": conversation[i]} for i in no_exact_match_list]\n        LLM_generated_answers.insert(0, {\"text\": gold_answer})\n\n        # create encodings by Llama-2-7b-hf guided by Prompts.A\n        doc_vecs = angle.encode(LLM_generated_answers, prompt=Prompts.A)\n\n        # Calculate cosine similarity, check if similarity score is low\n        for dv2 in doc_vecs[1:]:\n            cos_sim = cosine_similarity(doc_vecs[0], dv2)\n            if cos_sim < THRESHOLD:\n                return True\n    return False","metadata":{"execution":{"iopub.status.busy":"2024-09-23T20:50:56.487392Z","iopub.execute_input":"2024-09-23T20:50:56.487710Z","iopub.status.idle":"2024-09-23T20:50:56.498381Z","shell.execute_reply.started":"2024-09-23T20:50:56.487667Z","shell.execute_reply":"2024-09-23T20:50:56.497272Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Metrics","metadata":{}},{"cell_type":"markdown","source":"## Accuracy Calculation","metadata":{}},{"cell_type":"code","source":"def accuracy(conversations, gold_answers) -> float:\n    \"\"\" Calculates accuracy of LLMs according to their doubt\n\n        Parameters\n        ----------\n        conversations : List[List[str]]\n            The conversations with an LLM\n        gold_answers : List[str]\n            The real answers of the main questions in the conversations\n\n        Returns\n        -------\n        float\n            The accuracy of the conversations\n        \"\"\"\n    total_passes = 0\n    for conversation, gold_answer in zip(conversations, gold_answers):\n        if not hasDoubt(conversation, gold_answer):\n            total_passes += 1\n            \n    return ((total_passes / len(conversations)) * 100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modification Calculation\nThe metrics where taken from the  Paper:  \nASK AGAIN, THEN FAIL: LARGE LANGUAGE MODELS’ VACILLATIONS IN JUDGMENT  \nCan be found in page 4","metadata":{}},{"cell_type":"code","source":"def modification(conversations_before, conversations_after, gold_answers, ret_acc_before=False):\n    \"\"\" Calculates modification of LLMs according to their doubt\n\n        Parameters\n        ----------\n        conversations_before : List[List[str]]\n            The conversations with an LLM before inducing doubt\n        conversations_after : List[List[str]]\n            The conversations with an LLM after inducing doubt\n        gold_answers : List[str]\n            The real answers of the main questions in the conversations\n        ret_acc_before: bool\n            when True the function will return also the accuracy of conversations before\n\n        Returns\n        -------\n        float, optional[float]\n            The modification of the conversations and the accuracy of conversations before\n        \"\"\"\n    accuracy_before = accuracy(conversations_before, gold_answers)\n    accuracy_after = accuracy(conversations_after, gold_answers)\n    \n    mod = accuracy_before - accuracy_after\n    if ret_acc_before:\n        return mod, accuracy_before\n    return mod","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Process Results Function","metadata":{}},{"cell_type":"code","source":"def processResults(all_conversations, gold_answers):\n    \"\"\" Calculate metrics and save results in a pandas DataFrame\n\n    Parameters\n    ----------\n    all_conversations : Dict[str, Tuple[List[str], List[str]]]\n        The conversations with all LLMs before and after inducing doubt\n    gold_answers : List[str]\n        The real answers of the main questions in the conversations\n\n    Returns\n    -------\n    Pandas DataFrame\n        The modification and modification rate of all LLMs\n    \"\"\"\n    \n    res = {'Modification': [], 'Modification Rate': []}\n    llm_ids = []\n    for (llm_id, (conversations_before, conversations_after)) in all_conversations.items():\n        \n        # Calc modification\n        mod, acc_before = modification(conversations_before, conversations_after, gold_answers, True)\n        \n        # Calc modification Rate\n        modRate = mod / acc_before\n        \n        # Append Results to dictionary\n        res['Modification'].append(mod)\n        res['Modification Rate'].append(modRate)\n        llm_ids.append(llm_id)\n        \n    # Convert dictionary to DataFrame\n    df = pd.DataFrame(res)\n    df.index = llm_ids\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main Script","metadata":{}},{"cell_type":"code","source":"df = processResults(all_conversations, gold_answers)\ndf ","metadata":{},"execution_count":null,"outputs":[]}]}