{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9726491,"sourceType":"datasetVersion","datasetId":5889639},{"sourceId":9726641,"sourceType":"datasetVersion","datasetId":5881217},{"sourceId":9766508,"sourceType":"datasetVersion","datasetId":5879652},{"sourceId":201479431,"sourceType":"kernelVersion"},{"sourceId":205808566,"sourceType":"kernelVersion"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from global_utils import CFG, load_pkl, write_to_pkl, load_eval_llm\nfrom datasets_manipulations import load_datasets\n\nfrom langchain_community.chat_message_histories import SQLChatMessageHistory\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nfrom langchain.llms import HuggingFaceEndpoint, HuggingFacePipeline\nfrom langchain_core.messages import HumanMessage, BaseMessage\nfrom langchain.evaluation.qa import QAEvalChain\n\nfrom transformers import AutoTokenizer, pipeline\nfrom huggingface_hub import login\n\nfrom datasets import Dataset\nimport accelerate\nimport warnings\nimport sqlite3\nimport random\nimport pickle\nimport shutil\nimport torch\nimport re\nimport os\n\nlogin(token=CFG.credentials['llama3.2'])\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-11-07T16:25:58.633467Z","iopub.execute_input":"2024-11-07T16:25:58.633873Z","iopub.status.idle":"2024-11-07T16:27:03.552003Z","shell.execute_reply.started":"2024-11-07T16:25:58.633828Z","shell.execute_reply":"2024-11-07T16:27:03.550972Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting langchain\n  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nCollecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n  Downloading langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\nCollecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.140-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.9.2)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.15->langchain)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\nCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (2.4)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\nDownloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.15-py3-none-any.whl (408 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\nDownloading langsmith-0.1.140-py3-none-any.whl (304 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.8/304.8 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, requests-toolbelt, langsmith, langchain-core, langchain-text-splitters, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: requests-toolbelt\n    Found existing installation: requests-toolbelt 0.10.1\n    Uninstalling requests-toolbelt-0.10.1:\n      Successfully uninstalled requests-toolbelt-0.10.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.3 requires cubinlinker, which is not installed.\ncudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.3.7 langchain-core-0.3.15 langchain-text-splitters-0.3.2 langsmith-0.1.140 packaging-24.1 requests-toolbelt-1.0.0\nCollecting langchain_community\n  Downloading langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.2)\nRequirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.5)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\nCollecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: langchain<0.4.0,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.3.7)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.3.15)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.1.140)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.6->langchain_community) (0.3.2)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.6->langchain_community) (2.9.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_community) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.4)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_community) (2.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain_community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain_community) (2.23.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.0)\nDownloading langchain_community-0.3.5-py3-none-any.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\nInstalling collected packages: httpx-sse, pydantic-settings, langchain_community\nSuccessfully installed httpx-sse-0.4.0 langchain_community-0.3.5 pydantic-settings-2.6.1\nCollecting langchain_huggingface\n  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.25.1)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.3.15)\nCollecting sentence-transformers>=2.6.0 (from langchain_huggingface)\n  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: tokenizers>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (0.20.0)\nRequirement already satisfied: transformers>=4.39.0 in /opt/conda/lib/python3.10/site-packages (from langchain_huggingface) (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.1.140)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.9.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (8.3.0)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.14.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (10.3.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain_huggingface) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.5)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.4)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.10.4)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.8.30)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.2.0)\nDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\nDownloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.8/255.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers, langchain_huggingface\nSuccessfully installed langchain_huggingface-0.1.2 sentence-transformers-3.2.1\nThe token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load Datasets","metadata":{}},{"cell_type":"code","source":"random.seed(CFG.seed)\n\ndatasets_to_load = CFG.supported_datasets # CSQA | GSM8K | SQuAD_v1 | SQuAD_v2 | HotpotQA\nqa_lists = load_datasets(datasets_to_load, n_csqa=5000)\n\nall_questions = {}\nall_gold_answers = {}\nall_examples = {}\nall_configs = {}\n\nfor key in datasets_to_load:\n\n    qa = qa_lists[key]\n    used_idxs = set()\n    \n    questions = []\n    gold_answers = []\n    examples = []\n    configs = []\n\n    # Sample CFG.n entries\n    for _ in range(CFG.n):\n        while True:\n            idx = random.randint(0, len(qa)-1)\n            if idx not in used_idxs:\n                questions.append(qa[idx]['question'])\n                gold_answers.append(qa[idx]['correct_answer'])\n                examples.append({\"question\": qa[idx]['question']})\n                used_idxs.add(idx)\n                break\n    configs = [{\"configurable\": {\"session_id\": f\"{i+1}\"}} for i in range(len(examples))]\n    \n    all_questions[key] = questions\n    all_gold_answers[key] = gold_answers\n    all_examples[key] = examples\n    all_configs[key] = configs","metadata":{"execution":{"iopub.status.busy":"2024-11-07T16:27:55.816435Z","iopub.execute_input":"2024-11-07T16:27:55.816839Z","iopub.status.idle":"2024-11-07T16:31:03.899116Z","shell.execute_reply.started":"2024-11-07T16:27:55.816801Z","shell.execute_reply":"2024-11-07T16:31:03.898266Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4672ed0f910141cbb3e1bc7c13582e46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/1.25M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a4044ad710f46ab98f6a8b76e66b06e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/160k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2daebd1c14847169ca6215d243d5db2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/151k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bff02098881945dbbf4d3fd61095e957"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/9741 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8e6196eb9a7494d88fdbac8a5d84be8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1221 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a99d58cfa27475da01c8598610fc1a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1140 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87f5ff013dcc41168d41aa25a3e8769e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecbc4f7f105c480d9153697bc26b41b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d532bb64049416291c29004adf8be17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0ab087edec2423887b9c2f83db7819a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49f2f24ece444b8fb1eef40a353da4d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51e1745992474fefb5f0770b201ab307"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9942f5b74a5d40d9a1f6336064656a6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38c143cc25714f9c81bb125282df8338"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/1.82M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25acc326348a41b8836b1be1a94f54c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"428ddd3b0185469388b4b4a03fb6aa83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c09685dd15684766865ecd36c077bce2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5903c00edcb04067830f050d38a9871d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/16.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75a5aa125cbd4818a45137862afa1ea9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/1.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c2851d8dc4a40ada94749b6e198c243"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b225180583a4d4f99d2e6036a5cda6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06582b16e2a84a22b77433d8823240f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"hotpot_qa.py:   0%|          | 0.00/6.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"470580c33b3c45e4bdd795c30ca55cf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/9.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0e99da4b8004be8950f400697a72bd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/566M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f23964ac77d48cc96bb93ebaf8e33ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/46.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb65ebf5d4de4143ae4d89080a36b76a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/90447 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78b342476ff742f997dd6dcd3121ed7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/7405 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dbd09dad5424fdf8990c717e13c1587"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Define LLMs","metadata":{}},{"cell_type":"markdown","source":"## Llama 3.2","metadata":{}},{"cell_type":"code","source":"tokenizer=AutoTokenizer.from_pretrained(CFG.model)\n\n# Check if pad_token_id is missing, and set it to eos_token_id if needed\nif tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id\n    \npl = pipeline(\n    \"text-generation\",\n    model=CFG.model,\n    tokenizer=tokenizer,\n    return_full_text=False,\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=True,\n    device_map=\"auto\",\n    no_repeat_ngram_size=3,\n    max_new_tokens=150,\n    do_sample=False,\n    num_return_sequences=1,\n    eos_token_id=tokenizer.eos_token_id,\n    repetition_penalty=1.1,\n    )\n\nllm = HuggingFacePipeline(pipeline=pl)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T12:01:48.351555Z","iopub.execute_input":"2024-10-31T12:01:48.351994Z","iopub.status.idle":"2024-10-31T12:04:26.567464Z","shell.execute_reply.started":"2024-10-31T12:01:48.351944Z","shell.execute_reply":"2024-10-31T12:04:26.566503Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c734b8187574501928b5f480170f2f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c946481231fb46efb17d9dff9591c7e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc6066df3baa4dfb96aac0ff601ce06b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a891b4ed1f34cca8f6b4dbff00ba6b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c37e2d68372424ab30a2b7a03141924"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26fff4bcc4ea4f949445697203c9329b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49bd8e1b8e7c40d78aaa39a247683f27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"241351c2af0d4803a6d73355da503c3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34a620b4912e49d98b3b6ecdc73207c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d8032eafe214b8da4416b33d5de06e7"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Define DB Functions","metadata":{}},{"cell_type":"code","source":"def get_session_history(session_id):\n    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")\n\ndef update_db(human_messages, ai_messages):\n    # Check if a memory database already exists.\n    file_path = f'/kaggle/input/filtered-data-before-doubt/{key}/memory.db'\n    if os.path.exists(file_path):\n        # Load memory.db to working folder\n        shutil.copy(file_path, '/kaggle/working/')\n        delete_except_first_two()\n    else:\n        for session_id, question in enumerate(human_messages):\n            db = get_session_history(f'{session_id+1}')\n            db.add_messages([BaseMessage(content=question, type='human'),\n                             BaseMessage(content=ai_messages[session_id]['text'], type='ai')])\n    \ndef delete_except_first_two():\n    # Connect to the SQLite database\n    conn = sqlite3.connect('memory.db')\n    cursor = conn.cursor()\n    \n    # Step 1: Identify the message ids to delete (rank > 2 per session)\n    cursor.execute(\"\"\"\n        WITH ranked_messages AS (\n          SELECT\n            id,\n            ROW_NUMBER() OVER (PARTITION BY session_id ORDER BY id ASC) AS rn\n          FROM message_store\n        )\n        SELECT id\n        FROM ranked_messages\n        WHERE rn > 2;\n    \"\"\")\n    \n    ids_to_delete = cursor.fetchall()\n    \n    if ids_to_delete:\n        # Step 2: Execute the DELETE statement for all ids except the first two\n        cursor.executemany(\"\"\"\n            DELETE FROM message_store\n            WHERE id = ?;\n        \"\"\", [(row[0],) for row in ids_to_delete])\n        \n        conn.commit()\n        print(f\"Deleted {cursor.rowcount} messages.\")\n    else:\n        print(\"No messages to delete.\")\n    \n    # Close the connection\n    conn.close()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T12:04:26.568672Z","iopub.execute_input":"2024-10-31T12:04:26.569027Z","iopub.status.idle":"2024-10-31T12:04:26.578455Z","shell.execute_reply.started":"2024-10-31T12:04:26.568989Z","shell.execute_reply":"2024-10-31T12:04:26.577633Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Define Chain","metadata":{}},{"cell_type":"code","source":"def get_llm_chain(key):\n    prefix = CFG.prefixes_map[key]\n    assert prefix != None, CFG.error_messages['prefix'].format(key=key)\n    \n    prompt = ChatPromptTemplate.from_messages(\n        [\n            (\"system\", prefix),\n            MessagesPlaceholder(variable_name=\"history\"),\n            (\"human\", \"{question}\"),\n        ]\n    )\n\n    runnable = prompt | llm\n\n    chain = RunnableWithMessageHistory(\n        runnable,\n        get_session_history,\n        input_messages_key=\"question\",\n        history_messages_key=\"history\",\n    )\n    \n    return chain","metadata":{"execution":{"iopub.status.busy":"2024-10-31T12:04:26.579410Z","iopub.execute_input":"2024-10-31T12:04:26.579683Z","iopub.status.idle":"2024-10-31T12:04:26.594934Z","shell.execute_reply.started":"2024-10-31T12:04:26.579653Z","shell.execute_reply":"2024-10-31T12:04:26.594015Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# LLM Intergration","metadata":{}},{"cell_type":"markdown","source":"## Get LLM Answer","metadata":{}},{"cell_type":"code","source":"def get_answer(llm, questions, configs):\n    predictions = llm.batch(\n        questions,\n        config=configs,\n    )\n    return [{'text': pred} for pred in predictions]","metadata":{"execution":{"iopub.status.busy":"2024-10-31T12:04:26.595976Z","iopub.execute_input":"2024-10-31T12:04:26.596296Z","iopub.status.idle":"2024-10-31T12:04:26.608539Z","shell.execute_reply.started":"2024-10-31T12:04:26.596263Z","shell.execute_reply":"2024-10-31T12:04:26.607747Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Conversations Before Doubt     ","metadata":{}},{"cell_type":"code","source":"# Conversations Before Doubt     \ndef get_conversations_before(key, chain, questions, examples, configs):\n    file_path = f'/kaggle/input/conversations-before/conversations_before_{key}.pkl'\n    if not os.path.exists(file_path):\n        conversations_before = get_answer(chain, examples, configs)\n    else:\n        # Loading conversations_before\n        conversations_before = load_pkl(file_path)\n        if not os.path.exists('/kaggle/working/memory.db'):\n            update_db(questions, conversations_before)\n    return conversations_before","metadata":{"execution":{"iopub.status.busy":"2024-10-31T12:04:26.609518Z","iopub.execute_input":"2024-10-31T12:04:26.609827Z","iopub.status.idle":"2024-10-31T12:04:26.620374Z","shell.execute_reply.started":"2024-10-31T12:04:26.609796Z","shell.execute_reply":"2024-10-31T12:04:26.619519Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Extract Only Correct Answers  ","metadata":{}},{"cell_type":"markdown","source":"### Evaluate conversations before  ","metadata":{}},{"cell_type":"code","source":"def evaluate(key, questions, gold_answers):\n    # Initialize QAEvalChain\n    qa_eval_chain = load_eval_llm()\n\n    # Prepare examples (questions with gold answers)\n    if key == 'GSM8K':\n        examples_test = [ {\"question\": q, \"answer\": r.split('#### ')[-1]} for q, r in zip(questions, gold_answers)]\n    else:\n        examples_test = [ {\"question\": q, \"answer\": r} for q, r in zip(questions, gold_answers)]\n\n    # Convert to Datasets objects to improve efficiency\n    examples_test = Dataset.from_list(examples_test)\n    conversations_before_test = Dataset.from_list(conversations_before)\n\n    # Evaluate the model-generated answers by passing 'predictions' separately\n    eval_results = qa_eval_chain.evaluate(examples=examples_test,\n                                          predictions=conversations_before_test,\n                                          question_key=\"question\",\n                                          prediction_key=\"text\")\n\n    return eval_results","metadata":{"execution":{"iopub.status.busy":"2024-10-31T12:04:26.621537Z","iopub.execute_input":"2024-10-31T12:04:26.622150Z","iopub.status.idle":"2024-10-31T12:04:26.631711Z","shell.execute_reply.started":"2024-10-31T12:04:26.622107Z","shell.execute_reply":"2024-10-31T12:04:26.630865Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Filter Incorrect Responses","metadata":{}},{"cell_type":"code","source":"def filter_data(key, conversations_before, eval_results, questions, gold_answers, configs):\n    \n    file_path = f'/kaggle/input/filtered-data-before-doubt/{key}'\n    filtered_configs = []\n    if not os.path.exists(file_path):\n        filtered_conversations_before = []\n        filtered_questions = []\n        filtered_gold_answers = []\n        for conv, res, q, a, conf in zip(conversations_before, eval_results, questions, gold_answers, configs):\n            temp = res['results'].lower()\n            if 'correct' in temp and 'incorrect' not in temp:\n                filtered_conversations_before.append(conv)\n                filtered_questions.append(q)\n                filtered_gold_answers.append(a)\n                filtered_configs.append(conf)\n\n    else:\n        # Loading filtered conversations_before\n        filtered_conversations_before = load_pkl(f'/kaggle/input/filtered-data-before-doubt/{key}/filtered_conversations_before_{key}.pkl')\n        # Loading filtered questions\n        filtered_questions = load_pkl(f'/kaggle/input/filtered-data-before-doubt/{key}/filtered_questions_{key}.pkl')\n        # Loading filtered gold answers\n        filtered_gold_answers = load_pkl(f'/kaggle/input/filtered-data-before-doubt/{key}/filtered_gold_answers_{key}.pkl')\n\n        filtered_questions_set = set(filtered_questions)\n        for session_id in range(1, CFG.n+1):\n            q = (get_session_history(f'{session_id}').get_messages()[0]).content\n            if q in filtered_questions_set:\n                filtered_configs.append({\"configurable\": {\"session_id\": f\"{session_id}\"}})\n\n    # build filtered examples\n    filtered_examples = [{\"question\": q} for q in filtered_questions]\n    return filtered_conversations_before, filtered_questions, filtered_gold_answers, filtered_configs, filtered_examples","metadata":{"execution":{"iopub.status.busy":"2024-10-31T12:04:26.634736Z","iopub.execute_input":"2024-10-31T12:04:26.635109Z","iopub.status.idle":"2024-10-31T12:04:26.646618Z","shell.execute_reply.started":"2024-10-31T12:04:26.635078Z","shell.execute_reply":"2024-10-31T12:04:26.645812Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Conversations After Doubt","metadata":{}},{"cell_type":"code","source":"def get_conversation_after_doubt(llm, configs, experiment, questions, conversations_before=None):\n    \n    def update_history(_llm, _questions, _configs, history):\n        qs = Dataset.from_list(_questions)\n        preds = get_answer(_llm, qs, _configs)\n        for i, pred in enumerate(preds):\n            history[i].append(pred['text'])\n            \n    if conversations_before is None:\n        history = [[] for _ in range(len(questions))] # idx i: history of question i\n        update_history(llm, questions, configs, history)\n    else:\n        history = [[ans['text']] for ans in conversations_before]\n    \n    for idx, induced_doubt in enumerate(experiment):\n        print(f\"Generateing answers for induced doubt question {idx+1}/{len(experiment)}\")\n        induced_doubts = []\n        for hist in history:\n            hist.append(induced_doubt)\n            induced_doubts.append({\"question\": induced_doubt})\n        update_history(llm, induced_doubts, configs, history)\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-10-31T12:21:50.190169Z","iopub.execute_input":"2024-10-31T12:21:50.191252Z","iopub.status.idle":"2024-10-31T12:21:50.204503Z","shell.execute_reply.started":"2024-10-31T12:21:50.191206Z","shell.execute_reply":"2024-10-31T12:21:50.202141Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"all_conversations = {}\n\nfor key in datasets_to_load:\n    if key == 'SQuAD_v1':\n        continue\n    print(key)\n    questions = all_questions[key]\n    gold_answers = all_gold_answers[key]\n    examples = all_examples[key]\n    configs = all_configs[key]\n    \n    # Define chain\n    chain = get_llm_chain(key)\n    \n    # Get conversations before and memory database\n    conversations_before = get_conversations_before(key, chain, questions, examples, configs)\n    \n    # Evaluate results and receive filtering initial incorrect responses\n    eval_results = None\n    if not os.path.exists(f'/kaggle/input/filtered-data-before-doubt/{key}'):\n        eval_results = evaluate(key, questions, gold_answers)\n    \n    # Filter incorrect responses \n    data = filter_data(key, conversations_before, eval_results, questions, gold_answers, configs)\n    filtered_conversations_before, filtered_questions, filtered_gold_answers, filtered_configs, filtered_examples = data\n    \n    # Sanity check \n    print('Sanity Check - should print the same lengths:')\n    print(len(filtered_questions), len(filtered_gold_answers), len(filtered_configs))\n    \n    \n    # Get conversations after doubt\n    file_path = f'/kaggle/input/conversations-after/conversations_after_{key}.pkl'\n    if os.path.exists(file_path):\n        conversations_after = []\n        for idx, exp in enumerate(CFG.experiments):\n            print(f'Experiment {idx+1}/{len(CFG.experiments)}')\n            if key == 'GSM8K':\n                filtered_conversations_before = filtered_conversations_before[:220]\n            conversations_after.append(get_conversation_after_doubt(chain, filtered_configs, exp, filtered_questions, filtered_conversations_before))\n            # delete experiment history from all sessions expect for the main question and first response\n            delete_except_first_two() \n    else:\n        # Loading the data from a pickle file\n        conversations_after = load_pkl(file_path)\n    \n    # Delete memory database\n    !rm -rf memory.db\n    \n    all_conversations[key] = [filtered_conversations_before, conversations_after, filtered_questions, filtered_gold_answers]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save Data For Evaluation","metadata":{}},{"cell_type":"code","source":"for key in datasets_to_load:\n    if key == 'SQuAD_v1':\n        continue\n    write_to_pkl(f'filtered_conversations_before_{key}', all_conversations[key][0])\n    write_to_pkl(f'conversations_after_{key}', all_conversations[key][1])\n    write_to_pkl(f'filtered_questions_{key}', all_conversations[key][2])\n    write_to_pkl(f'filtered_gold_answers_{key}', all_conversations[key][3])\nprint('Done')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T20:57:18.856752Z","iopub.execute_input":"2024-10-31T20:57:18.857651Z","iopub.status.idle":"2024-10-31T20:57:18.870941Z","shell.execute_reply.started":"2024-10-31T20:57:18.857606Z","shell.execute_reply":"2024-10-31T20:57:18.869910Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}]}]}